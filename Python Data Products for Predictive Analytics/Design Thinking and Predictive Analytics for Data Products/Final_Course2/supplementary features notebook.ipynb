{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-62d017118966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m   {\n\u001b[1;32m     24\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"code\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m    \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m    \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Supplementary Notebook: Features\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook will familiarize you with the dataset you will be using in the Recommender System notebook in this course. Most of this should be review from courses 2 & 3, but this should be a good refresher for those who may have forgotten. We will discuss how to obtain certain features from our data using the dataset found here. https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### The Data: Amazon Video Game Reviews\\n\",\n",
    "    \"\\n\",\n",
    "    \"This dataset is a series of reviews and ratings from Amazon.\\n\",\n",
    "    \"\\n\",\n",
    "    \"We will import the data and set up our dataset below.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import gzip\\n\",\n",
    "    \"path = \\\"path\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"f = gzip.open(path, 'rt', encoding=\\\"utf8\\\")\\n\",\n",
    "    \"header = f.readline()\\n\",\n",
    "    \"header = header.strip().split('\\\\t')\\n\",\n",
    "    \"dataset = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for line in f:\\n\",\n",
    "    \"    fields = line.strip().split('\\\\t')\\n\",\n",
    "    \"    d = dict(zip(header, fields))\\n\",\n",
    "    \"    dataset.append(d)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"In the next cell we will display our header. This header is a list of the features that each element in our dataset. The following cell will display how to view an entry, and the one after that how to get a specific value out of an entry.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#list of features\\n\",\n",
    "    \"header\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#general format of dataset entry\\n\",\n",
    "    \"dataset[0]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#pulling a feature out of\\n\",\n",
    "    \"dataset[0]['product_title']\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Lets see how many data entries contain a 'NA' value by creating a second dataset which ignores entries with 'NA' values.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#this function will help with the below dataset cleaning\\n\",\n",
    "    \"def cleaned(datum, feat_list):\\n\",\n",
    "    \"    for f in feat_list:\\n\",\n",
    "    \"        if datum[f] == 'NA':\\n\",\n",
    "    \"            return False\\n\",\n",
    "    \"    return True\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataset_cleaned = [d for d in dataset if cleaned(d, header)]\\n\",\n",
    "    \"\\n\",\n",
    "    \"len(dataset) == len(dataset_cleaned)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Notice the two are equal! This is because the amazon datasets used in this course are pre-cleaned. Meaning that they contain no missing values. You may not always have this with your data, so be sure to clean your data before using!\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Try this!\\n\",\n",
    "    \"\\n\",\n",
    "    \"Next, try to write a function that replaces any 'NA' value of an entry with the average. (Note: The amazon data does have text entries as well but we'll use the new feature set defined below, which only cover a few numerical columns.) \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"num_features = ['star_rating','helpful_votes','total_votes']\\n\",\n",
    "    \"\\n\",\n",
    "    \"#notice avg is an input here, so it would be calculated outside of this for each individual feature\\n\",\n",
    "    \"def replace_w_avg(datum, feat_list, avg_list):\\n\",\n",
    "    \"    ### YOUR CODE HERE\\n\",\n",
    "    \"    #Note, datum is a dictionary entry and all lengths are the same between the lists and \\n\",\n",
    "    \"    #the number of key/value pairs\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#Test for previous function\\n\",\n",
    "    \"test_dat = [{'star_rating': 3, 'helpful_votes': 3, 'total_votes': 0},\\n\",\n",
    "    \"            {'star_rating': 2, 'helpful_votes': 4, 'total_votes': 3},\\n\",\n",
    "    \"            {'star_rating': 3, 'helpful_votes': 2, 'total_votes': 3},\\n\",\n",
    "    \"            {'star_rating': 2, 'helpful_votes': 4, 'total_votes': 1},\\n\",\n",
    "    \"            {'star_rating': 4, 'helpful_votes': 1, 'total_votes': 2}]\\n\",\n",
    "    \"#note this was randomly generated such that each numeric value was an int between 0-4\\n\",\n",
    "    \"\\n\",\n",
    "    \"# the calculated averages\\n\",\n",
    "    \"avg_list = [2.8, 2.8, 1.8]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"test_datum = {'star_rating': 'NA', 'helpful_votes': 3, 'total_votes': 'NA'}\\n\",\n",
    "    \"\\n\",\n",
    "    \"replace_w_avg(test_datum, num_features, avg_list) == {'star_rating': 2.8, 'helpful_votes': 3, 'total_votes': 1.8}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## There we go!\\n\",\n",
    "    \"\\n\",\n",
    "    \"This should have been a quick refresher on data features, transformations, and missing values. This example is all based on Categorical data, but the same principles apply for each feature which would represent a time step (similar to the rating:month example in the Temporal data video.)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.7.1\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
